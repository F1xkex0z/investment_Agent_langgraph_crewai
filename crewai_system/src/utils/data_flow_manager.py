"""
æ•°æ®æµç®¡ç†å™¨
è´Ÿè´£ç®¡ç†ä»»åŠ¡é—´çš„æ•°æ®ä¼ é€’å’Œå…±äº«ä¸Šä¸‹æ–‡çš„ä¸€è‡´æ€§
"""

from typing import Any, Dict, List, Optional
from datetime import datetime
import json

from crewai_system.src.utils.shared_context import get_global_context
from crewai_system.src.utils.logging_config import get_logger


class DataFlowManager:
    """æ•°æ®æµç®¡ç†å™¨"""

    def __init__(self):
        self.logger = get_logger("data")
        self.shared_context = get_global_context()

        # æ•°æ®é”®æ˜ å°„è§„åˆ™
        self.key_mappings = {
            "market_data": "{ticker}_market_data",
            "news_data": "{ticker}_news_data",
            "technical_analysis": "{ticker}_technical_analysis",
            "fundamentals_analysis": "{ticker}_fundamentals_analysis",
            "sentiment_analysis": "{ticker}_sentiment_analysis",
            "valuation_analysis": "{ticker}_valuation_analysis"
        }

        # æ•°æ®ä¾èµ–å…³ç³»
        self.data_dependencies = {
            "technical_analysis": ["market_data"],
            "fundamentals_analysis": ["market_data"],
            "sentiment_analysis": ["news_data", "market_data"],
            "valuation_analysis": ["market_data", "fundamentals_analysis"]
        }

        # æ•°æ®éªŒè¯è§„åˆ™
        self.validation_rules = {
            "market_data": self._validate_market_data,
            "news_data": self._validate_news_data,
            "technical_analysis": self._validate_technical_analysis,
            "fundamentals_analysis": self._validate_fundamentals_analysis,
            "sentiment_analysis": self._validate_sentiment_analysis,
            "valuation_analysis": self._validate_valuation_analysis
        }

    def store_data(self, data_type: str, ticker: str, data: Dict[str, Any],
                   source_agent: str, metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        å­˜å‚¨æ•°æ®åˆ°å…±äº«ä¸Šä¸‹æ–‡

        Args:
            data_type: æ•°æ®ç±»å‹
            ticker: è‚¡ç¥¨ä»£ç 
            data: æ•°æ®å†…å®¹
            source_agent: æ•°æ®æ¥æºæ™ºèƒ½ä½“
            metadata: å…ƒæ•°æ®

        Returns:
            å­˜å‚¨æ˜¯å¦æˆåŠŸ
        """
        self.logger.info(f"ğŸ” [DEBUG] ===== å¼€å§‹å­˜å‚¨æ•°æ® =====")
        self.logger.info(f"ğŸ” [DEBUG] data_type: {data_type}, ticker: {ticker}, source_agent: {source_agent}")
        self.logger.info(f"ğŸ” [DEBUG] åŸå§‹æ•°æ®å¤§å°: {len(str(data)) if data else 0}")

        try:
            key = self._get_data_key(data_type, ticker)
            self.logger.info(f"ğŸ” [DEBUG] ç”Ÿæˆå­˜å‚¨key: {key}")

            # éªŒè¯æ•°æ®
            self.logger.info(f"ğŸ” [DEBUG] å¼€å§‹éªŒè¯æ•°æ®...")
            if not self._validate_data(data_type, data):
                self.logger.warning(f"ğŸ” [DEBUG] æ•°æ®éªŒè¯å¤±è´¥: {data_type} for {ticker}")
                return False
            self.logger.info(f"ğŸ” [DEBUG] æ•°æ®éªŒè¯é€šè¿‡")

            # æ·»åŠ å­˜å‚¨å…ƒæ•°æ®
            enriched_data = {
                "content": data,
                "metadata": {
                    "data_type": data_type,
                    "ticker": ticker,
                    "source_agent": source_agent,
                    "storage_time": datetime.now().isoformat(),
                    "version": "1.0"
                }
            }

            if metadata:
                enriched_data["metadata"].update(metadata)

            # å­˜å‚¨æ•°æ®
            self.logger.info(f"ğŸ” [DEBUG] å­˜å‚¨æ•°æ®åˆ°å…±äº«ä¸Šä¸‹æ–‡...")
            self.shared_context.set(
                key=key,
                value=enriched_data,
                source_agent=source_agent,
                data_type=data_type
            )

            self.logger.info(f"ğŸ” [DEBUG] æ•°æ®å­˜å‚¨æˆåŠŸ: {key}")

            # å¦‚æœæ˜¯æ–°é—»æ•°æ®ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
            if data_type == "news_data":
                news_count = len(data) if isinstance(data, list) else 0
                self.logger.info(f"ğŸ” [DEBUG] æ–°é—»æ•°æ®å­˜å‚¨: æ•°é‡={news_count}, ticker={ticker}")
                if isinstance(data, list) and news_count > 0:
                    self.logger.info(f"ğŸ” [DEBUG] ç¬¬ä¸€æ¡æ–°é—»æ ‡é¢˜: {data[0].get('title', 'æ— æ ‡é¢˜')[:50]}...")

            return True

        except Exception as e:
            self.logger.error(f"ğŸ” [DEBUG] æ•°æ®å­˜å‚¨å¤±è´¥: {data_type} for {ticker}, é”™è¯¯: {e}")
            import traceback
            self.logger.error(f"ğŸ” [DEBUG] è¯¦ç»†é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return False

    def retrieve_data(self, data_type: str, ticker: str,
                     require_valid: bool = True) -> Optional[Dict[str, Any]]:
        """
        ä»å…±äº«ä¸Šä¸‹æ–‡æ£€ç´¢æ•°æ®

        Args:
            data_type: æ•°æ®ç±»å‹
            ticker: è‚¡ç¥¨ä»£ç 
            require_valid: æ˜¯å¦è¦æ±‚æ•°æ®æœ‰æ•ˆ

        Returns:
            æ£€ç´¢åˆ°çš„æ•°æ®æˆ–None
        """
        self.logger.info(f"ğŸ” [DEBUG] ===== å¼€å§‹æ£€ç´¢æ•°æ® =====")
        self.logger.info(f"ğŸ” [DEBUG] data_type: {data_type}, ticker: {ticker}, require_valid: {require_valid}")

        try:
            key = self._get_data_key(data_type, ticker)
            self.logger.info(f"ğŸ” [DEBUG] ç”Ÿæˆæ£€ç´¢key: {key}")

            data = self.shared_context.get(key, {})
            self.logger.info(f"ğŸ” [DEBUG] ä»å…±äº«ä¸Šä¸‹æ–‡è·å–æ•°æ®: {'å­˜åœ¨' if data else 'ä¸å­˜åœ¨'}")

            if not data:
                self.logger.warning(f"ğŸ” [DEBUG] æ•°æ®ä¸å­˜åœ¨: {key}")
                return None

            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if require_valid:
                self.logger.info(f"ğŸ” [DEBUG] å¼€å§‹éªŒè¯æ•°æ®å®Œæ•´æ€§...")
                if not self._validate_data(data_type, data.get("content", {})):
                    self.logger.warning(f"ğŸ” [DEBUG] æ£€ç´¢åˆ°çš„æ•°æ®æ— æ•ˆ: {key}")
                    return None
                self.logger.info(f"ğŸ” [DEBUG] æ•°æ®éªŒè¯é€šè¿‡")

            # å¦‚æœæ˜¯æ–°é—»æ•°æ®ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
            if data_type == "news_data":
                content = data.get("content", [])
                news_count = len(content) if isinstance(content, list) else 0
                self.logger.info(f"ğŸ” [DEBUG] æ–°é—»æ•°æ®æ£€ç´¢: æ•°é‡={news_count}, ticker={ticker}")
                if isinstance(content, list) and news_count > 0:
                    self.logger.info(f"ğŸ” [DEBUG] æ£€ç´¢åˆ°çš„ç¬¬ä¸€æ¡æ–°é—»æ ‡é¢˜: {content[0].get('title', 'æ— æ ‡é¢˜')[:50]}...")

            self.logger.info(f"ğŸ” [DEBUG] æ•°æ®æ£€ç´¢æˆåŠŸ: {key}")
            return data

        except Exception as e:
            self.logger.error(f"ğŸ” [DEBUG] æ•°æ®æ£€ç´¢å¤±è´¥: {data_type} for {ticker}, é”™è¯¯: {e}")
            import traceback
            self.logger.error(f"ğŸ” [DEBUG] è¯¦ç»†é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return None

    def check_data_availability(self, data_type: str, ticker: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥æ•°æ®å¯ç”¨æ€§

        Args:
            data_type: æ•°æ®ç±»å‹
            ticker: è‚¡ç¥¨ä»£ç 

        Returns:
            æ•°æ®å¯ç”¨æ€§ä¿¡æ¯
        """
        try:
            data = self.retrieve_data(data_type, ticker, require_valid=False)

            if data is None:
                return {
                    "available": False,
                    "reason": "data_not_found",
                    "quality": "none"
                }

            content = data.get("content", {})
            metadata = data.get("metadata", {})

            # æ£€æŸ¥æ•°æ®è´¨é‡
            quality = self._assess_data_quality(data_type, content)

            return {
                "available": True,
                "quality": quality,
                "source_agent": metadata.get("source_agent"),
                "storage_time": metadata.get("storage_time"),
                "data_size": len(json.dumps(content, default=str))
            }

        except Exception as e:
            self.logger.error(f"æ£€æŸ¥æ•°æ®å¯ç”¨æ€§å¤±è´¥: {data_type} for {ticker}, é”™è¯¯: {e}")
            return {
                "available": False,
                "reason": "check_failed",
                "error": str(e),
                "quality": "none"
            }

    def get_missing_dependencies(self, data_type: str, ticker: str) -> List[str]:
        """
        è·å–ç¼ºå¤±çš„ä¾èµ–æ•°æ®

        Args:
            data_type: æ•°æ®ç±»å‹
            ticker: è‚¡ç¥¨ä»£ç 

        Returns:
            ç¼ºå¤±çš„ä¾èµ–åˆ—è¡¨
        """
        missing = []

        if data_type not in self.data_dependencies:
            return missing

        for dependency in self.data_dependencies[data_type]:
            availability = self.check_data_availability(dependency, ticker)
            if not availability["available"] or availability["quality"] == "poor":
                missing.append(dependency)

        return missing

    def ensure_data_dependencies(self, data_type: str, ticker: str) -> bool:
        """
        ç¡®ä¿æ•°æ®ä¾èµ–æ»¡è¶³

        Args:
            data_type: æ•°æ®ç±»å‹
            ticker: è‚¡ç¥¨ä»£ç 

        Returns:
            ä¾èµ–æ˜¯å¦æ»¡è¶³
        """
        missing = self.get_missing_dependencies(data_type, ticker)

        if missing:
            self.logger.warning(f"æ•°æ®ä¾èµ–ç¼ºå¤±: {data_type} éœ€è¦ {missing}")
            return False

        return True

    def get_data_summary(self, ticker: str) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šè‚¡ç¥¨çš„æ•°æ®æ‘˜è¦

        Args:
            ticker: è‚¡ç¥¨ä»£ç 

        Returns:
            æ•°æ®æ‘˜è¦
        """
        summary = {
            "ticker": ticker,
            "data_types": {},
            "overall_quality": "unknown",
            "completeness": 0.0
        }

        quality_scores = []

        for data_type in self.key_mappings.keys():
            availability = self.check_data_availability(data_type, ticker)
            summary["data_types"][data_type] = availability

            if availability["available"]:
                quality_map = {"excellent": 5, "good": 4, "fair": 3, "poor": 2, "minimal": 1}
                quality = availability.get("quality", "none")
                if quality in quality_map:
                    quality_scores.append(quality_map[quality])

        # è®¡ç®—æ•´ä½“è´¨é‡
        if quality_scores:
            avg_quality = sum(quality_scores) / len(quality_scores)
            if avg_quality >= 4.5:
                summary["overall_quality"] = "excellent"
            elif avg_quality >= 3.5:
                summary["overall_quality"] = "good"
            elif avg_quality >= 2.5:
                summary["overall_quality"] = "fair"
            else:
                summary["overall_quality"] = "poor"

        # è®¡ç®—å®Œæ•´æ€§
        available_count = sum(1 for d in summary["data_types"].values() if d["available"])
        summary["completeness"] = available_count / len(self.key_mappings)

        return summary

    def cleanup_expired_data(self, ticker: str, ttl_hours: int = 24) -> int:
        """
        æ¸…ç†è¿‡æœŸæ•°æ®

        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            ttl_hours: ç”Ÿå­˜æ—¶é—´ï¼ˆå°æ—¶ï¼‰

        Returns:
            æ¸…ç†çš„æ•°æ®æ•°é‡
        """
        try:
            cutoff_time = datetime.now().timestamp() - (ttl_hours * 3600)
            cleaned_count = 0

            for data_type in self.key_mappings.keys():
                key = self._get_data_key(data_type, ticker)
                data = self.shared_context.get(key, {})

                if data:
                    metadata = data.get("metadata", {})
                    storage_time = metadata.get("storage_time")

                    if storage_time:
                        try:
                            storage_timestamp = datetime.fromisoformat(storage_time).timestamp()
                            if storage_timestamp < cutoff_time:
                                self.shared_context.delete(key)
                                cleaned_count += 1
                                self.logger.debug(f"æ¸…ç†è¿‡æœŸæ•°æ®: {key}")
                        except:
                            pass

            return cleaned_count

        except Exception as e:
            self.logger.error(f"æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {ticker}, é”™è¯¯: {e}")
            return 0

    def _get_data_key(self, data_type: str, ticker: str) -> str:
        """è·å–æ•°æ®é”®"""
        template = self.key_mappings.get(data_type, "{ticker}_{data_type}")
        return template.format(ticker=ticker, data_type=data_type)

    def _validate_data(self, data_type: str, data: Dict[str, Any]) -> bool:
        """éªŒè¯æ•°æ®"""
        validator = self.validation_rules.get(data_type)
        if validator:
            return validator(data)
        return True  # é»˜è®¤éªŒè¯é€šè¿‡

    def _assess_data_quality(self, data_type: str, data: Dict[str, Any]) -> str:
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        # åŸºç¡€è´¨é‡è¯„ä¼°
        if not data or not isinstance(data, dict):
            return "none"

        # æ ¹æ®æ•°æ®ç±»å‹è¿›è¡Œç‰¹å®šè¯„ä¼°
        if data_type == "market_data":
            return self._assess_market_data_quality(data)
        elif data_type == "news_data":
            return self._assess_news_data_quality(data)
        elif data_type == "technical_analysis":
            return self._assess_technical_analysis_quality(data)
        elif data_type == "fundamentals_analysis":
            return self._assess_fundamentals_analysis_quality(data)
        elif data_type == "sentiment_analysis":
            return self._assess_sentiment_analysis_quality(data)
        elif data_type == "valuation_analysis":
            return self._assess_valuation_analysis_quality(data)

        return "fair"

    def _validate_market_data(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯å¸‚åœºæ•°æ®"""
        required_fields = ["ticker", "collection_time"]
        for field in required_fields:
            if field not in data:
                return False

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»·æ ¼æˆ–è´¢åŠ¡æ•°æ®
        has_prices = "prices" in data and isinstance(data["prices"], list) and len(data["prices"]) > 0
        has_financial = "financial_metrics" in data and isinstance(data["financial_metrics"], dict)

        return has_prices or has_financial

    def _validate_news_data(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯æ–°é—»æ•°æ®"""
        if not isinstance(data, list):
            return False

        # æ£€æŸ¥æ–°é—»æ¡ç›®
        for news_item in data:
            if not isinstance(news_item, dict):
                return False
            if "title" not in news_item:
                return False

        return len(data) > 0

    def _validate_technical_analysis(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯æŠ€æœ¯åˆ†ææ•°æ®"""
        required_fields = ["analysis_result"]
        for field in required_fields:
            if field not in data:
                return False

        analysis_result = data["analysis_result"]
        if not isinstance(analysis_result, dict):
            return False

        return "trends" in analysis_result or "indicators" in analysis_result

    def _validate_fundamentals_analysis(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯åŸºæœ¬é¢åˆ†ææ•°æ®"""
        required_fields = ["analysis_result"]
        for field in required_fields:
            if field not in data:
                return False

        analysis_result = data["analysis_result"]
        if not isinstance(analysis_result, dict):
            return False

        return "quality_score" in analysis_result or "financial_health" in analysis_result

    def _validate_sentiment_analysis(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯æƒ…ç»ªåˆ†ææ•°æ®"""
        required_fields = ["analysis_result"]
        for field in required_fields:
            if field not in data:
                return False

        analysis_result = data["analysis_result"]
        if not isinstance(analysis_result, dict):
            return False

        return "overall_sentiment" in analysis_result or "sentiment_distribution" in analysis_result

    def _validate_valuation_analysis(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯ä¼°å€¼åˆ†ææ•°æ®"""
        required_fields = ["analysis_result"]
        for field in required_fields:
            if field not in data:
                return False

        analysis_result = data["analysis_result"]
        if not isinstance(analysis_result, dict):
            return False

        return "valuation_methods" in analysis_result or "investment_metrics" in analysis_result

    def _assess_market_data_quality(self, data: Dict[str, Any]) -> str:
        """è¯„ä¼°å¸‚åœºæ•°æ®è´¨é‡"""
        score = 0

        # è¯„ä¼°ä»·æ ¼æ•°æ®
        prices = data.get("prices", [])
        if prices and len(prices) > 100:
            score += 3
        elif prices and len(prices) > 20:
            score += 1

        # è¯„ä¼°è´¢åŠ¡æ•°æ®
        financial_metrics = data.get("financial_metrics", {})
        if financial_metrics and len(financial_metrics) > 10:
            score += 3
        elif financial_metrics and len(financial_metrics) > 3:
            score += 1

        # è¯„ä¼°å¸‚åœºä¿¡æ¯
        market_info = data.get("market_info", {})
        if market_info and market_info.get("market_cap", 0) > 0:
            score += 2

        # è¯„ä¼°ç»Ÿè®¡ä¿¡æ¯
        statistics = data.get("statistics", {})
        if statistics:
            score += 1

        if score >= 7:
            return "excellent"
        elif score >= 5:
            return "good"
        elif score >= 3:
            return "fair"
        else:
            return "poor"

    def _assess_news_data_quality(self, data: Dict[str, Any]) -> str:
        """è¯„ä¼°æ–°é—»æ•°æ®è´¨é‡"""
        if not isinstance(data, list):
            return "poor"

        score = min(len(data), 5)  # æœ€å¤š5åˆ†

        # æ£€æŸ¥æ–°é—»å®Œæ•´æ€§
        complete_news = 0
        for news in data:
            if isinstance(news, dict) and news.get("title") and news.get("content"):
                complete_news += 1

        if complete_news == len(data) and len(data) >= 5:
            score += 2
        elif complete_news >= len(data) * 0.7:
            score += 1

        if score >= 6:
            return "excellent"
        elif score >= 4:
            return "good"
        elif score >= 2:
            return "fair"
        else:
            return "poor"

    def _assess_technical_analysis_quality(self, data: Dict[str, Any]) -> str:
        """è¯„ä¼°æŠ€æœ¯åˆ†æè´¨é‡"""
        analysis_result = data.get("analysis_result", {})
        score = 0

        # è¯„ä¼°è¶‹åŠ¿åˆ†æ
        trends = analysis_result.get("trends", {})
        if trends:
            score += 2

        # è¯„ä¼°æŒ‡æ ‡åˆ†æ
        indicators = analysis_result.get("indicators", {})
        if indicators:
            score += 2

        # è¯„ä¼°ä¿¡å·å¼ºåº¦
        signal_strength = analysis_result.get("signal_strength", 0)
        if signal_strength > 0.7:
            score += 2
        elif signal_strength > 0.4:
            score += 1

        if score >= 5:
            return "excellent"
        elif score >= 3:
            return "good"
        elif score >= 1:
            return "fair"
        else:
            return "poor"

    def _assess_fundamentals_analysis_quality(self, data: Dict[str, Any]) -> str:
        """è¯„ä¼°åŸºæœ¬é¢åˆ†æè´¨é‡"""
        analysis_result = data.get("analysis_result", {})
        score = 0

        # è¯„ä¼°è´¨é‡è¯„åˆ†
        quality_score = analysis_result.get("quality_score", 0)
        if quality_score > 70:
            score += 3
        elif quality_score > 50:
            score += 2
        elif quality_score > 30:
            score += 1

        # è¯„ä¼°è´¢åŠ¡å¥åº·
        financial_health = analysis_result.get("financial_health", {})
        if financial_health:
            score += 2

        # è¯„ä¼°é£é™©å› ç´ 
        risk_factors = analysis_result.get("risk_factors", [])
        if risk_factors:
            score += 1

        if score >= 5:
            return "excellent"
        elif score >= 3:
            return "good"
        elif score >= 1:
            return "fair"
        else:
            return "poor"

    def _assess_sentiment_analysis_quality(self, data: Dict[str, Any]) -> str:
        """è¯„ä¼°æƒ…ç»ªåˆ†æè´¨é‡"""
        analysis_result = data.get("analysis_result", {})
        score = 0

        # è¯„ä¼°æƒ…ç»ªåˆ†æ•°
        overall_sentiment = analysis_result.get("overall_sentiment", 0)
        if overall_sentiment != 0:
            score += 2

        # è¯„ä¼°æƒ…ç»ªåˆ†å¸ƒ
        sentiment_distribution = analysis_result.get("sentiment_distribution", {})
        if sentiment_distribution:
            score += 2

        # è¯„ä¼°æ–°é—»è¦†ç›–
        news_coverage = analysis_result.get("news_coverage", {})
        if news_coverage:
            score += 1

        if score >= 4:
            return "excellent"
        elif score >= 2:
            return "good"
        elif score >= 1:
            return "fair"
        else:
            return "poor"

    def _assess_valuation_analysis_quality(self, data: Dict[str, Any]) -> str:
        """è¯„ä¼°ä¼°å€¼åˆ†æè´¨é‡"""
        analysis_result = data.get("analysis_result", {})
        score = 0

        # è¯„ä¼°ä¼°å€¼æ–¹æ³•
        valuation_methods = analysis_result.get("valuation_methods", {})
        if valuation_methods:
            score += 2

        # è¯„ä¼°æŠ•èµ„æŒ‡æ ‡
        investment_metrics = analysis_result.get("investment_metrics", {})
        if investment_metrics:
            score += 2

        # è¯„ä¼°ä¼°å€¼ç­‰çº§
        investment_metrics = analysis_result.get("investment_metrics", {})
        valuation_grade = investment_metrics.get("valuation_grade")
        if valuation_grade in ["undervalued", "fairly_valued", "overvalued"]:
            score += 1

        if score >= 4:
            return "excellent"
        elif score >= 2:
            return "good"
        elif score >= 1:
            return "fair"
        else:
            return "poor"


# å…¨å±€æ•°æ®æµç®¡ç†å™¨å®ä¾‹
data_flow_manager = DataFlowManager()


def get_data_flow_manager() -> DataFlowManager:
    """è·å–å…¨å±€æ•°æ®æµç®¡ç†å™¨å®ä¾‹"""
    return data_flow_manager